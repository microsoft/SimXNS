{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92874557",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542ce71c",
   "metadata": {},
   "source": [
    "## Step 1: Prepare the training dataset for QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92b9312",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_list = []\n",
    "\n",
    "for qid in trange(len(dataset)):\n",
    "    example = {}\n",
    "    \n",
    "    positive_ctxs = []\n",
    "    \n",
    "    example['question'] = dataset[qid]['question']\n",
    "    \n",
    "    example['answers'] = dataset[qid]['answer']\n",
    "        \n",
    "    train_data_list.append(example)\n",
    "\n",
    "with open(f'/{data_path}/biencoder-dataset-train.json', 'w', encoding='utf-8') as json_file:\n",
    "      json_file.write(json.dumps(train_data_list, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a951ff",
   "metadata": {},
   "source": [
    "## Step 2: Retrieve the initial documents and generate the training data for dense retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c2f93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Please follow the instruction in LEAD (https://github.com/microsoft/SimXNS/tree/main/LEAD)\n",
    "\n",
    "## bash retrieve_hard_negatives_academic.sh $DATASET $MASTER_PORT $MODEL_PATH $CKPT_NAME $MAX_DOC_LENGTH $MAX_QUERY_LENGTH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c017de6",
   "metadata": {},
   "source": [
    "## Step 3: Train the retriever using the generated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866ad0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Please follow the instruction in LEAD (https://github.com/microsoft/SimXNS/tree/main/LEAD)\n",
    "\n",
    "## bash train_12_layer_de.sh $DATASET $MASTER_PORT $MAX_DOC_LENGTH $MAX_QUERY_LENGTH $TRAIN_BATCH_SIZE $NUM_NEGATIVES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d370f43",
   "metadata": {},
   "source": [
    "## Step 4: Output the embedding file using the trained checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47e70ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Please follow the instruction in LEAD (https://github.com/microsoft/SimXNS/tree/main/LEAD)\n",
    "\n",
    "## bash evaluate_12_layer_de.sh $DATASET $MASTER_PORT $MODEL_PATH $FIRST_STEPS  $EVAL_STEPS $MAX_STEPS $MAX_DOC_LENGTH $MAX_QUERY_LENGTH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab021dbd",
   "metadata": {},
   "source": [
    "## Step 5: Merge the inference the embedding file as follow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23acb765",
   "metadata": {},
   "outputs": [],
   "source": [
    "passage_embedding_list = []\n",
    "passage_embedding_id_list = []\n",
    "for i in trange(N): \n",
    "    pickle_path = os.path.join(f'/{data_path}/', \"{1}_data_obj_{0}.pb\".format(str(i), 'passage_embedding'))\n",
    "    with open(pickle_path, 'rb') as handle:\n",
    "        b = pickle.load(handle)\n",
    "        passage_embedding_list.append(b)\n",
    "for i in trange(N): \n",
    "    pickle_path = os.path.join(f'/{data_path}/', \"{1}_data_obj_{0}.pb\".format(str(i), 'passage_embedding_id'))\n",
    "    with open(pickle_path, 'rb') as handle:\n",
    "        b = pickle.load(handle)\n",
    "        passage_embedding_id_list.append(b)\n",
    "passage_embedding = np.concatenate(passage_embedding_list, axis=0)\n",
    "passage_embedding_id = np.concatenate(passage_embedding_id_list, axis=0)\n",
    "\n",
    "with open(f'/{data_path}/passage_embedding.pb', 'wb') as f:\n",
    "    pickle.dump(passage_embedding, f)\n",
    "f.close()\n",
    "\n",
    "with open(f'/{data_path}/passage_embedding2id.pb', 'wb') as f:\n",
    "    pickle.dump(passage_embedding_id, f)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
